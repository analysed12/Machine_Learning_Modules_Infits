{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeveloperVivek9/Calorie-Tracker/blob/main/Deployment/Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IihJqsx3IgH",
        "outputId": "54238e8f-b043-4d1a-a9d6-df8342748fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 30 kB 39.7 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 61 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 71 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 122 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 123 kB 12.7 MB/s \n",
            "\u001b[?25halbumentations==1.3.0 is successfully installed\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U albumentations\n",
        "!echo \"$(pip freeze | grep albumentations) is successfully installed\"\n",
        "!pip install detecto --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "from detecto.utils import xml_to_csv\n",
        "#from google.colab import drive\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import re\n",
        "import shutil"
      ],
      "metadata": {
        "id": "N5VXqGVVBBX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PROBLEMS SOLVED\n",
        "#Transformed images of Images having different extensions will be in jpg which may cause problems. Conserve extension info\n",
        "#Logic not written for images with multiple bounding boxes. \n",
        "#       Transformed images getting saved again and again if it faces multiple bounding boxes.\n",
        "#       Image id is not image id here but rather it's the number of additions onto csv\n",
        "#If already transformed, it will do transformation on that file which will cause problems\n",
        "#Name of image changed to function name so that we get accurate information from name itself \n",
        "#else too many if statements needed which decrease readability\n",
        "#4. Sometimes transformed bndbox empty. Is it because random rotation or something? \n",
        "#       We tested on the same image multiple times. Rotate alone giving no bounding box the second time onwards. [?]\n",
        "#Solution -> Just check length of what is returned. But why is this  happening?\n",
        "#1. Transform applied to each record in labels.csv which is optimal but transformed image created for each bndbox which is not.\n",
        "#       Create transformed images for each unique image\n",
        "#       Add transformed bounding boxes to csv\n",
        "# Solution -> don't save image if image already transformed. [dictionary where each key value -> transform name, value -> list of images done]\n",
        "#2. Why does compose require list(tuple())?? -> It should be because it is expecting multiple bndboxes \n",
        "#       since we are iterating for each bndbox, list not required, since it is expecting one, we should follow."
      ],
      "metadata": {
        "id": "l0OWx_0viEyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I don't want augmentations to be done along data entry function\n",
        "#Reason -> we won't be able to change augmentation functions or add more augmentations \n",
        "#Here logic written so that transformed images won't be transformed again. "
      ],
      "metadata": {
        "id": "bq9r4xqu_0YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ISSUES\n",
        "#3. Fix visualization function. Bounding box wrong. \n",
        "#When augmentation function gets changed, we should remove those transformed images and add them again. [logic for that should be written]\n",
        "#Tranform list changes should reflect in csv file too. Removing a transformation should delete those transformed images from csv file and delete them."
      ],
      "metadata": {
        "id": "Dkohad3094jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_bbox(img, bbox, class_name, BOX_COLOR,TEXT_COLOR, thickness=2):\n",
        "    x_min, y_min, w, h = bbox\n",
        "    x_min, x_max, y_min, y_max = int(x_min), int(x_min + w), int(y_min), int(y_min + h)\n",
        "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color=BOX_COLOR, thickness=thickness)\n",
        "    ((text_width, text_height), _) = cv2.getTextSize(class_name, cv2.FONT_HERSHEY_SIMPLEX, 0.35, 1)    \n",
        "    cv2.rectangle(img, (x_min, y_min - int(1.3 * text_height)), (x_min + text_width, y_min), BOX_COLOR, -1)\n",
        "    cv2.putText(\n",
        "        img,\n",
        "        text=class_name,\n",
        "        org=(x_min, y_min - int(0.3 * text_height)),\n",
        "        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
        "        fontScale=0.35, \n",
        "        color=TEXT_COLOR, \n",
        "        lineType=cv2.LINE_AA,\n",
        "    )\n",
        "    return img"
      ],
      "metadata": {
        "id": "2bkZMahrJzei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(image, bndbox,class_name,BOX_COLOR=(255, 0, 0),TEXT_COLOR=(255, 255, 255)):\n",
        "    img = image.copy()\n",
        "    img = visualize_bbox(img, bndbox,class_name,BOX_COLOR,TEXT_COLOR)\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img)"
      ],
      "metadata": {
        "id": "CRRgE219KDyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Augmentation functions used on the images. Note the name of the function which is what should be in total_transform_list.\n",
        "def Rotate():\n",
        "  return A.Compose([A.ShiftScaleRotate(always_apply=True,p=0.5)],bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "def HFlip():\n",
        "  return A.Compose([A.HorizontalFlip(always_apply=True,p=0.5)],bbox_params=A.BboxParams(format='pascal_voc'))\n",
        "\n",
        "def Brighten():\n",
        "  return A.Compose([A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, brightness_by_max=True, always_apply=True, p=0.5)],bbox_params=A.BboxParams(format='pascal_voc'))"
      ],
      "metadata": {
        "id": "I1HVv6kV0gK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data augmentation code \n",
        "def data_augment(img_path,class_name,bndbox_with_class,transform_name):\n",
        "  \"\"\"\n",
        "  Applies transform_name on the image. \n",
        "  Returns transformed image and transformed bounding boxes. \n",
        "  \"\"\"\n",
        "  image = cv2.imread(img_path)\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  #Calling relevant function\n",
        "  transform = globals()[transform_name] \n",
        "  #Calling the function\n",
        "  transform=transform()\n",
        "  #Applying transformation\n",
        "  transformed = transform(image=image, bboxes=[bndbox_with_class], class_labels=[class_name])\n",
        "  transformed_bboxes = transformed['bboxes']\n",
        "  transformed_image = transformed['image']\n",
        "  return transformed_image,transformed_bboxes #Return the transformed images,bboxes and the name"
      ],
      "metadata": {
        "id": "m2op1R4ML4oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Augmentation_function(base_path,Image_Metadata_csv,total_transform_list=['Brighten','HFlip','Rotate']):\n",
        "\n",
        "  \"\"\"\n",
        "  Augments images listed in Image Metadata.csv where base_path is the path of the csv file. \n",
        "  total_transform_list is the list of transformations we need to do on the images.\n",
        "  \"\"\"\n",
        "\n",
        "  #If image transformed, new name added to list. We use this to get image id.\n",
        "  transformed_images_list=list()\n",
        "\n",
        "  #Transform dict is to get transformations done on a particular image.\n",
        "  #key -> image name without extension.\n",
        "  #value -> list of transformations done on that image.\n",
        "  #We are assuming no transformation has been done on transformed images. [Better to create augmentation pipeline in the respective function instead of applying again]\n",
        "  labels=pd.read_csv(base_path+Image_Metadata_csv)\n",
        "  Transform_dict=dict()\n",
        "  for x in list(labels['Image Name']):\n",
        "    try:\n",
        "      Unique_id=x.replace(re.search(r\"[ A-Za-z]+\\.[A-Za-z]+\", x).group(),\"\")\n",
        "      transform_function=re.search(r\"[A-Za-z]+\\.[A-Za-z]+\", x).group().split('.', 1)[0] \n",
        "      Transform_dict[Unique_id].append(transform_function)\n",
        "    except KeyError:\n",
        "      Transform_dict[Unique_id]=list()\n",
        "      Unique_id=x.replace(re.search(r\"[ A-Za-z]+\\.[A-Za-z]+\", x).group(),\"\")\n",
        "      transform_function=re.search(r\"[A-Za-z]+\\.[A-Za-z]+\", x).group().split('.', 1)[0] \n",
        "      Transform_dict[Unique_id].append(transform_function)\n",
        "    except AttributeError:\n",
        "      continue\n",
        "  #print(Transform_dict)\n",
        "  #Start and end indices to get how many records added.   \n",
        "  start_index=labels['Image ID'].max()+1\n",
        "  end_index=start_index\n",
        "  #To traverse each bounding box in the dataframe\n",
        "  for index, row in labels.iterrows(): \n",
        "    image_name=row['Image Name']\n",
        "    class_name = row['Class']\n",
        "    image_path=row['Image Path']\n",
        "    bndbox_with_class = [row['xmin'],row['ymin'],row['xmax'],row['ymax'],row['Class']] \n",
        "    print(\"In \",row)\n",
        "    #Avoiding augmented images.\n",
        "    try:\n",
        "      #Regex to check if string after image id -> which means augmented image\n",
        "      transform_name=re.search(r\"[A-Za-z]+\\.[A-Za-z]+\", image_name).group().split('.', 1)[0]   \n",
        "      \"\"\"\n",
        "      if(transform_name not in total_transform_list):\n",
        "        os.remove(labels.loc[index,'Image Path'])\n",
        "        labels.drop(axis=0, index=index,inplace=True)\n",
        "      \"\"\"\n",
        "      continue \n",
        "    except AttributeError:\n",
        "      pass\n",
        "\n",
        "    try:\n",
        "      transform_list=[x for x in total_transform_list if x not in Transform_dict[os.path.splitext(image_name)[0]]]\n",
        "    except KeyError:\n",
        "      transform_list=total_transform_list\n",
        "\n",
        "    #Looping through transforms not done on that image :\n",
        "    #i) save transformed image if not saved \n",
        "    #ii) write transformed bounding box onto csv\n",
        "    for transform_name in transform_list:\n",
        "      print(\"Image name : \",image_name,\"Transform Name : \",transform_name)\n",
        "      transformed_image,transformed_bndbox = data_augment(image_path+image_name,class_name,bndbox_with_class,transform_name)\n",
        "      #print(transformed_bndbox,bndbox_with_class)\n",
        "      if(len(transformed_bndbox)<1):\n",
        "        #print(len(transformed_bndbox))\n",
        "        continue\n",
        "      name_of_file = os.path.splitext(image_name)[0] + \" \"+transform_name+os.path.splitext(image_name)[1]\n",
        "      if(name_of_file not in transformed_images_list):\n",
        "        transformed_images_list.append(name_of_file)       \n",
        "        im = Image.fromarray(transformed_image)\n",
        "        im.save(image_path+name_of_file)\n",
        "      image_id=start_index+transformed_images_list.index(name_of_file)\n",
        "      width = im.width\n",
        "      height = im.height\n",
        "      xmin,ymin,xmax,ymax= [int(x) for x in transformed_bndbox[0][0:4]]\n",
        "      labels.loc[len(labels.index)] = [len(labels.index),image_id,image_path,name_of_file,height,width,class_name,xmin,ymin,xmax,ymax,None]\n",
        "      end_index+=1\n",
        "  labels.to_csv(base_path+Image_Metadata_csv,encoding='utf-8',index=False)\n",
        "  return start_index,end_index"
      ],
      "metadata": {
        "id": "ZRLCYc8ZZafF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyr7_fO36zvx",
        "outputId": "13cf3aa3-d10b-4aac-eeea-920fb66e40a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "base_path='/content/drive/MyDrive/Experiment/Unannotated/'\n",
        "disparity_dir='/content/drive/MyDrive/Experiment/Disparity/'\n",
        "destination_dir='/content/drive/MyDrive/Experiment/Annotated/'\n",
        "Image_Metadata_csv='/content/drive/MyDrive/Experiment/Image Metadata.csv'\n",
        "Augmentation_function(destination_dir,Image_Metadata_csv)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfB9LR3u6Wjq",
        "outputId": "8f64a91c-5068-4433-e3b1-aa0b80e92494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In  Bndbox ID                                                0\n",
            "Image ID                                                 0\n",
            "Image Path    /content/drive/MyDrive/Experiment/Annotated/\n",
            "Image Name                             Aamla Murabba 0.jpg\n",
            "Height                                                 540\n",
            "Width                                                  720\n",
            "Class                                        Aamla Murabba\n",
            "xmin                                                   206\n",
            "ymin                                                     6\n",
            "xmax                                                   470\n",
            "ymax                                                   233\n",
            "Batch                                                  NaN\n",
            "Name: 0, dtype: object\n",
            "Image name :  Aamla Murabba 0.jpg Transform Name :  Brighten\n",
            "Image name :  Aamla Murabba 0.jpg Transform Name :  HFlip\n",
            "Image name :  Aamla Murabba 0.jpg Transform Name :  Rotate\n",
            "In  Bndbox ID                                                1\n",
            "Image ID                                                 1\n",
            "Image Path    /content/drive/MyDrive/Experiment/Annotated/\n",
            "Image Name                               Aaloo Chips 1.jpg\n",
            "Height                                                 549\n",
            "Width                                                  731\n",
            "Class                                          Aaloo Chips\n",
            "xmin                                                   378\n",
            "ymin                                                    57\n",
            "xmax                                                   613\n",
            "ymax                                                   189\n",
            "Batch                                                  NaN\n",
            "Name: 1, dtype: object\n",
            "Image name :  Aaloo Chips 1.jpg Transform Name :  Brighten\n",
            "Image name :  Aaloo Chips 1.jpg Transform Name :  HFlip\n",
            "Image name :  Aaloo Chips 1.jpg Transform Name :  Rotate\n",
            "In  Bndbox ID                                                2\n",
            "Image ID                                                 1\n",
            "Image Path    /content/drive/MyDrive/Experiment/Annotated/\n",
            "Image Name                               Aaloo Chips 1.jpg\n",
            "Height                                                 549\n",
            "Width                                                  731\n",
            "Class                                          Aaloo Chips\n",
            "xmin                                                   200\n",
            "ymin                                                   100\n",
            "xmax                                                   613\n",
            "ymax                                                   189\n",
            "Batch                                                  NaN\n",
            "Name: 2, dtype: object\n",
            "Image name :  Aaloo Chips 1.jpg Transform Name :  Brighten\n",
            "Image name :  Aaloo Chips 1.jpg Transform Name :  HFlip\n",
            "Image name :  Aaloo Chips 1.jpg Transform Name :  Rotate\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "labels=pd.read_csv(Image_Metadata_csv)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9UujpS-f_61j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for index, row in labels.iterrows(): \n",
        "    image_name=row['Image Name']\n",
        "    class_name = row['Class']\n",
        "    image_path=row['Image Path']+image_name\n",
        "    print(image_name)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GXsW9ZmAH-Z",
        "outputId": "820d8777-6f30-48d6-81bd-945885912be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aaloo Chips 0.jpg\n",
            "Aaloo Chips 0.jpg\n",
            "Aamla Murabba 1.jpg\n",
            "Aaloo Chips 0 Brighten.jpg\n",
            "Aaloo Chips 0 HFlip.jpg\n",
            "Aaloo Chips 0 Rotate.jpg\n",
            "Aamla Murabba 1 Brighten.jpg\n",
            "Aamla Murabba 1 HFlip.jpg\n",
            "Aamla Murabba 1 Rotate.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#Directory containing images  and xml files\n",
        "base_path=\"\"\n",
        "#csv file generated in Data Preprocessing Pipeline\n",
        "labels=pd.read_csv(\"Image Metadata.csv\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rs1Wlkv2AtV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}