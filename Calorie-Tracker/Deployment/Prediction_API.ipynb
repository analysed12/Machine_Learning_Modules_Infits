{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0 --quiet\n",
        "!pip install torchvision==0.10.0 --quiet\n",
        "!pip install detecto --quiet\n",
        "!pip install flask-ngrok --quiet\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.tgz --quiet\n",
        "!tar -xvf /content/ngrok-stable-linux-amd64.tgz\n",
        "!./ngrok authtoken 2J8RN9l5ZFgqSojAbd42thI8yvL_B6PBRuQwHYXBEvfik6Zx "
      ],
      "metadata": {
        "id": "RYJBx9a2Iro0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "686fa1db-6506-4140-d76e-2d21e60e1a94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 831.4 MB 14 kB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.14.0+cu116 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.13.0+cu116 requires torch==1.13.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 26.2 MB/s \n",
            "\u001b[?25hngrok\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1670162017697
        },
        "id": "Dkml4wiuwQxc"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from detecto import core, utils, visualize\n",
        "from detecto.visualize import show_labeled_image\n",
        "from detecto.utils import read_image\n",
        "from flask import Flask,request,jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate New_Images_List.csv\n",
        "#df = pd.DataFrame(columns=['image id','image name','class'])\n",
        "#df.to_csv('New_Images_List.csv',encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "SUy1IrTGWrI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#synonyms = class_df.loc[class_df['Class Name']==class1,'Synonym'].iloc[0]"
      ],
      "metadata": {
        "id": "iwcaB8YmYvJE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classes_list.csv, New_images_list.csv, model weights in the same folder as this file. \n",
        "drive.mount(\"/content/drive\")\n",
        "global base_path\n",
        "base_path=\"/content/drive/MyDrive/Augmentation/\"\n",
        "os.chdir(base_path)\n",
        "global image_path\n",
        "image_path=base_path+\"Unannotated/\"\n",
        "os.makedirs(image_path,exist_ok=True)\n",
        "global classes_list_df\n",
        "classes_list_df=pd.read_csv('/content/Classes_list.csv')\n",
        "global classes_list\n",
        "classes_list=list(classes_list_df['filename'])\n",
        "global images_list_df\n",
        "df = pd.DataFrame(columns=['image id','image name','class'])\n",
        "df.to_csv('New_Images_List.csv',encoding='utf-8', index=False)\n",
        "images_list_df=pd.read_csv('New_Images_List.csv')\n",
        "model = core.Model.load('model_weights_epochs_14_lr_0001_001.pth', classes_list) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6CjAwHP2HXN",
        "outputId": "11f630c6-592a-4ee1-90fe-2ae8c406b218"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CyQl5NJOYk48"
      },
      "outputs": [],
      "source": [
        "#If we were to return as a string, how should we separate the classes? Here we are using ','\n",
        "def predict(image_dir,image_name):\n",
        "  #image is numpy array\n",
        "  #image_name is name of the image\n",
        "  image=read_image(image_dir+image_name)\n",
        "  try:\n",
        "    image_count=images_list_df['image id'].iloc[-1]+1\n",
        "  except IndexError:\n",
        "    image_count=1\n",
        "  #cv2.imwrite(os.path.join(image_path ,\"User input image \"+str(image_count)+\".jpg\"), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
        "  #cv2.waitKey(0)\n",
        "  #images_list_df.loc[len(images_list_df.index)] = [image_count, \"User input image \"+str(image_count)+\".jpg\",None] \n",
        "  images_list_df.loc[len(images_list_df.index)] = [image_count,image_name,None]\n",
        "  images_list_df.to_csv('New_Images_List.csv',encoding='utf-8', index=False)\n",
        "  #print(image_dir+image_name)\n",
        "  predictions = model.predict(image)\n",
        "  labels, boxes, scores = predictions\n",
        "  #print(scores)\n",
        "  class_in_image=list()\n",
        "  class_in_image=[x for x in scores if x>0.6]\n",
        "  class_in_image=list(set(labels[0:len(class_in_image)]))\n",
        "  return class_in_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def class_in_list(s,string):\n",
        "  \"\"\"\n",
        "  Returns string in s. This is to see whether class name exists in list(class_name). \n",
        "  This written as a function so that we can apply it on the dataframe.\n",
        "  \"\"\"\n",
        "  return string in s"
      ],
      "metadata": {
        "id": "Zpd4pLIxkK0W"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "223M5m6IlG0e"
      },
      "outputs": [],
      "source": [
        "image_path=base_path+\"Unannotated/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "\n",
        "#The csv containing both class name and synonyms\n",
        "class_df = pd.read_csv(\"/content/drive/MyDrive/Augmentation/Classes_List.csv\")\n",
        "\n",
        "@app.route(\"/predict\",methods=['POST'])\n",
        "def show_class():\n",
        "    f = request.files['file'] \n",
        "    f.save(image_path+f.filename)  \n",
        "    classes = predict(image_path,f.filename)\n",
        "    synonyms=[]\n",
        "    for class_ in classes:\n",
        "      #class_df is the csv file containing the class name and the synonyms\n",
        "      if class_ in class_df['Class Name']:\n",
        "        synonyms.append(class_df.loc[class_df['Class Name']==class_,'Synonym'].iloc[0])\n",
        "        #print(\"In class name\")\n",
        "      elif class_ not in list(class_df['Class Name']):\n",
        "        #print(\"In synonym\")\n",
        "        if(class_df['Synonym'].apply(class_in_list,args=([class_])).any()):\n",
        "          i=class_df['Synonym'].apply(class_in_list,args=([class_]))\n",
        "          synonyms.append(class_df.loc[i]['Class Name'].iloc[0])\n",
        "    data = {\n",
        "            \"Img_name\" : f.filename,\n",
        "            \"Prediction\" : classes,\n",
        "            \"Alias\": synonyms\n",
        "        }\n",
        "    return jsonify(data)\n",
        "\n",
        "@app.route(\"/wrongclass\",methods=['POST'])\n",
        "def add_class():\n",
        "    f=request.get_data()\n",
        "    text_file = open(\"wrongclass.txt\", \"w\")\n",
        "    n = text_file.write(f.decode())\n",
        "    text_file.close()     \n",
        "    with open('wrongclass.txt', 'r') as text:\n",
        "      data = text.read().rstrip()\n",
        "      images_list_df.loc[len(images_list_df.index),'class']=data.split(',')\n",
        "      images_list_df.to_csv('New_Images_List.csv',encoding='utf-8', index=False)\n",
        "    return \"Success\"\n",
        "    \n",
        "@app.route(\"/helloworld\",methods=['POST'])\n",
        "def return_hello_world():\n",
        "  return \"Hello World!\"\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  app.run()\n",
        "  #app.run(host=HOST, port=PORT, threaded=True)"
      ],
      "metadata": {
        "id": "UgvPfPlXf4bT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0daf87-0eaf-4a92-f957-1f2e506362e2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://c8e2-34-143-243-110.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Jan/2023 12:32:45] \"\u001b[37mPOST /predict HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}