{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvSPSsxxWu1cTCa0Sr9Spf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"nfMxbOxKpo0m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666777027415,"user_tz":-330,"elapsed":65096,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"7fd07489-fca8-40ba-d02d-7c81abbde6bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-gpu\n","  Downloading tensorflow_gpu-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.27.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.0.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.17.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n","Collecting flatbuffers>=2.0\n","  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n","Collecting tensorboard<2.11,>=2.10\n","  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 48.9 MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n","  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n","\u001b[K     |████████████████████████████████| 438 kB 63.1 MB/s \n","\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.50.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n","Collecting keras<2.11,>=2.10.0\n","  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[K     |████████████████████████████████| 1.7 MB 56.1 MB/s \n","\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.8.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (3.4.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.6.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (1.35.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow-gpu) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow-gpu) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow-gpu) (3.2.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n","Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow-gpu\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.9.24 which is incompatible.\n","tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.10.0 which is incompatible.\n","tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.10.1 which is incompatible.\n","tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.10.0 which is incompatible.\u001b[0m\n","Successfully installed flatbuffers-22.9.24 keras-2.10.0 tensorboard-2.10.1 tensorflow-estimator-2.10.0 tensorflow-gpu-2.10.0\n"]}],"source":["!pip install tensorflow-gpu"]},{"cell_type":"code","source":["import tensorflow as tf\n","print(tf.__version__)"],"metadata":{"id":"3yRqHEl8qbVR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666777108280,"user_tz":-330,"elapsed":3199,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"38e0da71-b06a-4e24-d30c-0a6079d864b4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["2.10.0\n"]}]},{"cell_type":"markdown","source":["##**Cloning Tensorflow Object Detection (TFOD) 2.0 From GitHub**"],"metadata":{"id":"odPuocOdtAoK"}},{"cell_type":"code","source":["!git clone https://github.com/tensorflow/models.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Btnpe07wsus8","executionInfo":{"status":"ok","timestamp":1666777138762,"user_tz":-330,"elapsed":28337,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"92a40343-6e3d-4016-c6ad-9ae868553c08"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 78273, done.\u001b[K\n","remote: Counting objects: 100% (76/76), done.\u001b[K\n","remote: Compressing objects: 100% (43/43), done.\u001b[K\n","remote: Total 78273 (delta 40), reused 66 (delta 33), pack-reused 78197\u001b[K\n","Receiving objects: 100% (78273/78273), 593.50 MiB | 26.18 MiB/s, done.\n","Resolving deltas: 100% (55663/55663), done.\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"DZZnxxq9tUXZ","executionInfo":{"status":"ok","timestamp":1666777337878,"user_tz":-330,"elapsed":668,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"bd4ab9e9-f979-429e-8cd0-49937b0a2f72"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["cd /content/models/research"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AGAskQRrzW5W","executionInfo":{"status":"ok","timestamp":1666777353498,"user_tz":-330,"elapsed":966,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"de54b0e3-189d-4fdb-abe1-1db8873fe593"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","source":["!protoc object_detection/protos/*.proto --python_out=."],"metadata":{"id":"Ig0nDog3zsHF","executionInfo":{"status":"ok","timestamp":1666777356079,"user_tz":-330,"elapsed":489,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/cocodataset/cocoapi.git"],"metadata":{"id":"EoCqtV7B0cx9","executionInfo":{"status":"ok","timestamp":1666777395083,"user_tz":-330,"elapsed":2093,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"437b15bf-2cbd-499a-aeb3-c4a772b7f4a2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 23.49 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n"]}]},{"cell_type":"code","source":["cd cocoapi/PythonAPI"],"metadata":{"id":"UqmT0WyC1Lmh","executionInfo":{"status":"ok","timestamp":1666777399141,"user_tz":-330,"elapsed":873,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d8926445-91f8-423b-fc17-aff69521c04a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi/PythonAPI\n"]}]},{"cell_type":"code","source":["!make"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LI9hC22q1T_o","executionInfo":{"status":"ok","timestamp":1666777406416,"user_tz":-330,"elapsed":5027,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"b39c380e-0271-4111-fe13-fd01bd42d10c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.7\n","creating build/temp.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n","       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n","                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.7\n","creating build/lib.linux-x86_64-3.7/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"]}]},{"cell_type":"code","source":["cp -r pycocotools /content/models/research"],"metadata":{"id":"PZ5-ebjx1hfT","executionInfo":{"status":"ok","timestamp":1666777410455,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["##**Install the Object Detection API**"],"metadata":{"id":"FbwCuFug6y4-"}},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HKec6nMs69VG","executionInfo":{"status":"ok","timestamp":1666777678908,"user_tz":-330,"elapsed":698,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"eb89c145-d203-4811-9299-9f8008f3c64c"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/research/cocoapi/PythonAPI'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7KtRSal7GnQ","executionInfo":{"status":"ok","timestamp":1666777683439,"user_tz":-330,"elapsed":463,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"802ad000-88ce-4df1-9105-d5a1c6e792cd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CzOwflue7LRu","executionInfo":{"status":"ok","timestamp":1666777685296,"user_tz":-330,"elapsed":2,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"0761022d-a57f-4844-b046-f1b110000ee5"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","source":["cp object_detection/packages/tf2/setup.py ."],"metadata":{"id":"7RfrRc837OnN","executionInfo":{"status":"ok","timestamp":1666777687819,"user_tz":-330,"elapsed":776,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["!python -m pip install --use-feature=2020-resolver ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AiyYc5tB7Wt5","executionInfo":{"status":"ok","timestamp":1666777805591,"user_tz":-330,"elapsed":115981,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"99945ebb-de41-4781-a114-5e8b46045df2"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n","\u001b[K     |████████████████████████████████| 11.0 MB 16.2 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 65.9 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.5)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |████████████████████████████████| 2.2 MB 48.8 MB/s \n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n","\u001b[K     |████████████████████████████████| 25.0 MB 1.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.10.0)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n","\u001b[?25hCollecting sacrebleu<=2.2.0\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[K     |████████████████████████████████| 116 kB 67.4 MB/s \n","\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n","\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting tensorflow~=2.10.0\n","  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n","\u001b[K     |████████████████████████████████| 578.0 MB 16 kB/s \n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 60.6 MB/s \n","\u001b[?25hCollecting immutabledict\n","  Downloading immutabledict-2.2.1-py3-none-any.whl (4.0 kB)\n","Collecting opencv-python-headless==4.5.2.52\n","  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n","\u001b[K     |████████████████████████████████| 38.2 MB 1.3 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n","\u001b[K     |████████████████████████████████| 238 kB 68.1 MB/s \n","\u001b[?25hCollecting tensorflow-text~=2.10.0\n","  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n","\u001b[K     |████████████████████████████████| 5.9 MB 53.1 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 57.4 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.5)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.10.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.50.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (22.9.24)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[K     |████████████████████████████████| 2.4 MB 52.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n","Collecting cloudpickle~=2.1.0\n","  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 67.7 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n","\u001b[?25hCollecting proto-plus<2,>=1.7.1\n","  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n","\u001b[K     |████████████████████████████████| 47 kB 5.2 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Collecting orjson<4.0\n","  Downloading orjson-3.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n","\u001b[K     |████████████████████████████████| 272 kB 67.4 MB/s \n","\u001b[?25hCollecting zstandard<1,>=0.18.0\n","  Downloading zstandard-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n","\u001b[K     |████████████████████████████████| 2.5 MB 49.9 MB/s \n","\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n","\u001b[K     |████████████████████████████████| 508 kB 57.9 MB/s \n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting docopt\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","Collecting protobuf<4.0.0dev,>=3.12.0\n","  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 55.5 MB/s \n","\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.8.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n","Building wheels for collected packages: object-detection, dill, avro-python3, docopt, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696507 sha256=83ee414220c7a699fc2f49d44461a269b9845e987f0d440f2d7cad8ac59b9688\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-tzx32egq/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=42ed783064119b0412ce62eaaee5bf06298eaba4dd05c9e5de44fbf165828df8\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=831f472e1f85d0d7b7778949828cc70366d2c2abf224fc7aee71e7b1addb44cf\n","  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=4f1ef8abb1604ce31a6df834730f188187877bf4a38cd2f8b11ad056be07de45\n","  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=efd04901221a6f1fec5639c839163b10baa710ff61640053f334a966b7c792bd\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection dill avro-python3 docopt seqeval\n","Installing collected packages: requests, pyparsing, protobuf, tensorflow, portalocker, docopt, dill, colorama, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.17.3\n","    Uninstalling protobuf-3.17.3:\n","      Successfully uninstalled protobuf-3.17.3\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.5.1\n","    Uninstalling dill-0.3.5.1:\n","      Successfully uninstalled dill-0.3.5.1\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.3.2\n","    Uninstalling pymongo-4.3.2:\n","      Successfully uninstalled pymongo-4.3.2\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.6.0.66\n","    Uninstalling opencv-python-headless-4.6.0.66:\n","      Successfully uninstalled opencv-python-headless-4.6.0.66\n","  Attempting uninstall: cloudpickle\n","    Found existing installation: cloudpickle 1.5.0\n","    Uninstalling cloudpickle-1.5.0:\n","      Successfully uninstalled cloudpickle-1.5.0\n","Successfully installed apache-beam-2.42.0 avro-python3-1.10.2 cloudpickle-2.1.0 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.1 hdfs-2.7.0 immutabledict-2.2.1 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.1 portalocker-2.6.0 proto-plus-1.22.1 protobuf-3.19.6 py-cpuinfo-9.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0 zstandard-0.18.0\n"]}]},{"cell_type":"markdown","source":["##**Testing The Installation Of TFOD**"],"metadata":{"id":"M0dXFpvD9dg3"}},{"cell_type":"code","source":["!python object_detection/builders/model_builder_tf2_test.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5t2Lprfa7nzF","outputId":"80d86b82-32e2-4794-bf78-27ab1cf6f888","executionInfo":{"status":"ok","timestamp":1666777845350,"user_tz":-330,"elapsed":39770,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-26 09:52:05.363302: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-26 09:52:06.284085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-26 09:52:06.284255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-26 09:52:06.284276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Running tests under Python 3.7.15: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2022-10-26 09:52:10.416119: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W1026 09:52:10.789337 140145730971520 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.61s\n","I1026 09:52:11.050002 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.61s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.55s\n","I1026 09:52:11.598032 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.55s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n","I1026 09:52:11.892747 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.29s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.39s\n","I1026 09:52:12.282594 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.39s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.26s\n","I1026 09:52:15.543565 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.26s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I1026 09:52:15.549357 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I1026 09:52:15.579129 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I1026 09:52:15.601408 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I1026 09:52:15.618939 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n","I1026 09:52:15.717651 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n","I1026 09:52:15.813476 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n","I1026 09:52:15.914882 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","I1026 09:52:16.009623 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","I1026 09:52:16.111080 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I1026 09:52:16.143798 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I1026 09:52:16.330277 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1026 09:52:16.330493 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 64\n","I1026 09:52:16.330590 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n","I1026 09:52:16.332874 140145730971520 efficientnet_model.py:143] round_filter input=32 output=32\n","I1026 09:52:16.362177 140145730971520 efficientnet_model.py:143] round_filter input=32 output=32\n","I1026 09:52:16.362325 140145730971520 efficientnet_model.py:143] round_filter input=16 output=16\n","I1026 09:52:16.447859 140145730971520 efficientnet_model.py:143] round_filter input=16 output=16\n","I1026 09:52:16.448033 140145730971520 efficientnet_model.py:143] round_filter input=24 output=24\n","I1026 09:52:16.652450 140145730971520 efficientnet_model.py:143] round_filter input=24 output=24\n","I1026 09:52:16.652651 140145730971520 efficientnet_model.py:143] round_filter input=40 output=40\n","I1026 09:52:16.848932 140145730971520 efficientnet_model.py:143] round_filter input=40 output=40\n","I1026 09:52:16.849131 140145730971520 efficientnet_model.py:143] round_filter input=80 output=80\n","I1026 09:52:17.143020 140145730971520 efficientnet_model.py:143] round_filter input=80 output=80\n","I1026 09:52:17.143202 140145730971520 efficientnet_model.py:143] round_filter input=112 output=112\n","I1026 09:52:17.600020 140145730971520 efficientnet_model.py:143] round_filter input=112 output=112\n","I1026 09:52:17.600266 140145730971520 efficientnet_model.py:143] round_filter input=192 output=192\n","I1026 09:52:17.988940 140145730971520 efficientnet_model.py:143] round_filter input=192 output=192\n","I1026 09:52:17.989135 140145730971520 efficientnet_model.py:143] round_filter input=320 output=320\n","I1026 09:52:18.080971 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I1026 09:52:18.124773 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:18.175784 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I1026 09:52:18.175955 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 88\n","I1026 09:52:18.176034 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n","I1026 09:52:18.177610 140145730971520 efficientnet_model.py:143] round_filter input=32 output=32\n","I1026 09:52:18.196297 140145730971520 efficientnet_model.py:143] round_filter input=32 output=32\n","I1026 09:52:18.196453 140145730971520 efficientnet_model.py:143] round_filter input=16 output=16\n","I1026 09:52:18.361468 140145730971520 efficientnet_model.py:143] round_filter input=16 output=16\n","I1026 09:52:18.361657 140145730971520 efficientnet_model.py:143] round_filter input=24 output=24\n","I1026 09:52:18.637678 140145730971520 efficientnet_model.py:143] round_filter input=24 output=24\n","I1026 09:52:18.637874 140145730971520 efficientnet_model.py:143] round_filter input=40 output=40\n","I1026 09:52:18.917211 140145730971520 efficientnet_model.py:143] round_filter input=40 output=40\n","I1026 09:52:18.917406 140145730971520 efficientnet_model.py:143] round_filter input=80 output=80\n","I1026 09:52:19.282775 140145730971520 efficientnet_model.py:143] round_filter input=80 output=80\n","I1026 09:52:19.282963 140145730971520 efficientnet_model.py:143] round_filter input=112 output=112\n","I1026 09:52:19.658273 140145730971520 efficientnet_model.py:143] round_filter input=112 output=112\n","I1026 09:52:19.658476 140145730971520 efficientnet_model.py:143] round_filter input=192 output=192\n","I1026 09:52:20.108977 140145730971520 efficientnet_model.py:143] round_filter input=192 output=192\n","I1026 09:52:20.109161 140145730971520 efficientnet_model.py:143] round_filter input=320 output=320\n","I1026 09:52:20.296350 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I1026 09:52:20.333373 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:20.403595 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I1026 09:52:20.403767 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 112\n","I1026 09:52:20.403843 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n","I1026 09:52:20.405384 140145730971520 efficientnet_model.py:143] round_filter input=32 output=32\n","I1026 09:52:20.424968 140145730971520 efficientnet_model.py:143] round_filter input=32 output=32\n","I1026 09:52:20.425108 140145730971520 efficientnet_model.py:143] round_filter input=16 output=16\n","I1026 09:52:20.569862 140145730971520 efficientnet_model.py:143] round_filter input=16 output=16\n","I1026 09:52:20.570034 140145730971520 efficientnet_model.py:143] round_filter input=24 output=24\n","I1026 09:52:20.845216 140145730971520 efficientnet_model.py:143] round_filter input=24 output=24\n","I1026 09:52:20.845404 140145730971520 efficientnet_model.py:143] round_filter input=40 output=48\n","I1026 09:52:21.124694 140145730971520 efficientnet_model.py:143] round_filter input=40 output=48\n","I1026 09:52:21.124909 140145730971520 efficientnet_model.py:143] round_filter input=80 output=88\n","I1026 09:52:21.508834 140145730971520 efficientnet_model.py:143] round_filter input=80 output=88\n","I1026 09:52:21.509016 140145730971520 efficientnet_model.py:143] round_filter input=112 output=120\n","I1026 09:52:21.893433 140145730971520 efficientnet_model.py:143] round_filter input=112 output=120\n","I1026 09:52:21.893616 140145730971520 efficientnet_model.py:143] round_filter input=192 output=208\n","I1026 09:52:22.360083 140145730971520 efficientnet_model.py:143] round_filter input=192 output=208\n","I1026 09:52:22.360267 140145730971520 efficientnet_model.py:143] round_filter input=320 output=352\n","I1026 09:52:22.556659 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I1026 09:52:22.595336 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:22.658657 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I1026 09:52:22.658832 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 160\n","I1026 09:52:22.658910 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n","I1026 09:52:22.660652 140145730971520 efficientnet_model.py:143] round_filter input=32 output=40\n","I1026 09:52:22.682462 140145730971520 efficientnet_model.py:143] round_filter input=32 output=40\n","I1026 09:52:22.682587 140145730971520 efficientnet_model.py:143] round_filter input=16 output=24\n","I1026 09:52:22.845677 140145730971520 efficientnet_model.py:143] round_filter input=16 output=24\n","I1026 09:52:22.845863 140145730971520 efficientnet_model.py:143] round_filter input=24 output=32\n","I1026 09:52:23.126972 140145730971520 efficientnet_model.py:143] round_filter input=24 output=32\n","I1026 09:52:23.127159 140145730971520 efficientnet_model.py:143] round_filter input=40 output=48\n","I1026 09:52:23.597304 140145730971520 efficientnet_model.py:143] round_filter input=40 output=48\n","I1026 09:52:23.597512 140145730971520 efficientnet_model.py:143] round_filter input=80 output=96\n","I1026 09:52:24.066467 140145730971520 efficientnet_model.py:143] round_filter input=80 output=96\n","I1026 09:52:24.066664 140145730971520 efficientnet_model.py:143] round_filter input=112 output=136\n","I1026 09:52:24.549054 140145730971520 efficientnet_model.py:143] round_filter input=112 output=136\n","I1026 09:52:24.549253 140145730971520 efficientnet_model.py:143] round_filter input=192 output=232\n","I1026 09:52:25.097446 140145730971520 efficientnet_model.py:143] round_filter input=192 output=232\n","I1026 09:52:25.097634 140145730971520 efficientnet_model.py:143] round_filter input=320 output=384\n","I1026 09:52:25.284564 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I1026 09:52:25.321713 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:25.389173 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I1026 09:52:25.389344 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 224\n","I1026 09:52:25.389437 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n","I1026 09:52:25.391383 140145730971520 efficientnet_model.py:143] round_filter input=32 output=48\n","I1026 09:52:25.411972 140145730971520 efficientnet_model.py:143] round_filter input=32 output=48\n","I1026 09:52:25.412119 140145730971520 efficientnet_model.py:143] round_filter input=16 output=24\n","I1026 09:52:25.569458 140145730971520 efficientnet_model.py:143] round_filter input=16 output=24\n","I1026 09:52:25.569636 140145730971520 efficientnet_model.py:143] round_filter input=24 output=32\n","I1026 09:52:25.953489 140145730971520 efficientnet_model.py:143] round_filter input=24 output=32\n","I1026 09:52:25.953674 140145730971520 efficientnet_model.py:143] round_filter input=40 output=56\n","I1026 09:52:26.328196 140145730971520 efficientnet_model.py:143] round_filter input=40 output=56\n","I1026 09:52:26.328381 140145730971520 efficientnet_model.py:143] round_filter input=80 output=112\n","I1026 09:52:26.887201 140145730971520 efficientnet_model.py:143] round_filter input=80 output=112\n","I1026 09:52:26.887414 140145730971520 efficientnet_model.py:143] round_filter input=112 output=160\n","I1026 09:52:27.446620 140145730971520 efficientnet_model.py:143] round_filter input=112 output=160\n","I1026 09:52:27.446810 140145730971520 efficientnet_model.py:143] round_filter input=192 output=272\n","I1026 09:52:28.186563 140145730971520 efficientnet_model.py:143] round_filter input=192 output=272\n","I1026 09:52:28.186782 140145730971520 efficientnet_model.py:143] round_filter input=320 output=448\n","I1026 09:52:28.375132 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I1026 09:52:28.414664 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:28.494802 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I1026 09:52:28.495017 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 288\n","I1026 09:52:28.495129 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n","I1026 09:52:28.497589 140145730971520 efficientnet_model.py:143] round_filter input=32 output=48\n","I1026 09:52:28.519349 140145730971520 efficientnet_model.py:143] round_filter input=32 output=48\n","I1026 09:52:28.519494 140145730971520 efficientnet_model.py:143] round_filter input=16 output=24\n","I1026 09:52:28.739724 140145730971520 efficientnet_model.py:143] round_filter input=16 output=24\n","I1026 09:52:28.739908 140145730971520 efficientnet_model.py:143] round_filter input=24 output=40\n","I1026 09:52:29.196051 140145730971520 efficientnet_model.py:143] round_filter input=24 output=40\n","I1026 09:52:29.196233 140145730971520 efficientnet_model.py:143] round_filter input=40 output=64\n","I1026 09:52:29.667265 140145730971520 efficientnet_model.py:143] round_filter input=40 output=64\n","I1026 09:52:29.667460 140145730971520 efficientnet_model.py:143] round_filter input=80 output=128\n","I1026 09:52:30.560900 140145730971520 efficientnet_model.py:143] round_filter input=80 output=128\n","I1026 09:52:30.561099 140145730971520 efficientnet_model.py:143] round_filter input=112 output=176\n","I1026 09:52:31.385200 140145730971520 efficientnet_model.py:143] round_filter input=112 output=176\n","I1026 09:52:31.385450 140145730971520 efficientnet_model.py:143] round_filter input=192 output=304\n","I1026 09:52:32.495043 140145730971520 efficientnet_model.py:143] round_filter input=192 output=304\n","I1026 09:52:32.495239 140145730971520 efficientnet_model.py:143] round_filter input=320 output=512\n","I1026 09:52:32.791517 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I1026 09:52:32.831331 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:32.918359 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I1026 09:52:32.918539 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 384\n","I1026 09:52:32.918617 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n","I1026 09:52:32.920181 140145730971520 efficientnet_model.py:143] round_filter input=32 output=56\n","I1026 09:52:32.941200 140145730971520 efficientnet_model.py:143] round_filter input=32 output=56\n","I1026 09:52:32.941327 140145730971520 efficientnet_model.py:143] round_filter input=16 output=32\n","I1026 09:52:33.166566 140145730971520 efficientnet_model.py:143] round_filter input=16 output=32\n","I1026 09:52:33.166780 140145730971520 efficientnet_model.py:143] round_filter input=24 output=40\n","I1026 09:52:33.715278 140145730971520 efficientnet_model.py:143] round_filter input=24 output=40\n","I1026 09:52:33.715467 140145730971520 efficientnet_model.py:143] round_filter input=40 output=72\n","I1026 09:52:34.274163 140145730971520 efficientnet_model.py:143] round_filter input=40 output=72\n","I1026 09:52:34.274345 140145730971520 efficientnet_model.py:143] round_filter input=80 output=144\n","I1026 09:52:35.028860 140145730971520 efficientnet_model.py:143] round_filter input=80 output=144\n","I1026 09:52:35.029048 140145730971520 efficientnet_model.py:143] round_filter input=112 output=200\n","I1026 09:52:35.785456 140145730971520 efficientnet_model.py:143] round_filter input=112 output=200\n","I1026 09:52:35.785649 140145730971520 efficientnet_model.py:143] round_filter input=192 output=344\n","I1026 09:52:36.818976 140145730971520 efficientnet_model.py:143] round_filter input=192 output=344\n","I1026 09:52:36.819190 140145730971520 efficientnet_model.py:143] round_filter input=320 output=576\n","I1026 09:52:37.106687 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I1026 09:52:37.144304 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1026 09:52:37.240625 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I1026 09:52:37.240797 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 384\n","I1026 09:52:37.240892 140145730971520 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n","I1026 09:52:37.242526 140145730971520 efficientnet_model.py:143] round_filter input=32 output=64\n","I1026 09:52:37.263056 140145730971520 efficientnet_model.py:143] round_filter input=32 output=64\n","I1026 09:52:37.263206 140145730971520 efficientnet_model.py:143] round_filter input=16 output=32\n","I1026 09:52:37.565291 140145730971520 efficientnet_model.py:143] round_filter input=16 output=32\n","I1026 09:52:37.565478 140145730971520 efficientnet_model.py:143] round_filter input=24 output=48\n","I1026 09:52:38.468413 140145730971520 efficientnet_model.py:143] round_filter input=24 output=48\n","I1026 09:52:38.468610 140145730971520 efficientnet_model.py:143] round_filter input=40 output=80\n","I1026 09:52:39.129044 140145730971520 efficientnet_model.py:143] round_filter input=40 output=80\n","I1026 09:52:39.129242 140145730971520 efficientnet_model.py:143] round_filter input=80 output=160\n","I1026 09:52:40.048287 140145730971520 efficientnet_model.py:143] round_filter input=80 output=160\n","I1026 09:52:40.048493 140145730971520 efficientnet_model.py:143] round_filter input=112 output=224\n","I1026 09:52:40.980375 140145730971520 efficientnet_model.py:143] round_filter input=112 output=224\n","I1026 09:52:40.980582 140145730971520 efficientnet_model.py:143] round_filter input=192 output=384\n","I1026 09:52:42.187134 140145730971520 efficientnet_model.py:143] round_filter input=192 output=384\n","I1026 09:52:42.187342 140145730971520 efficientnet_model.py:143] round_filter input=320 output=640\n","I1026 09:52:42.579173 140145730971520 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I1026 09:52:42.629175 140145730971520 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.61s\n","I1026 09:52:42.752756 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 26.61s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I1026 09:52:42.780631 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I1026 09:52:42.782451 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I1026 09:52:42.783003 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I1026 09:52:42.785146 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I1026 09:52:42.787140 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I1026 09:52:42.787744 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I1026 09:52:42.789216 140145730971520 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 33.355s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"code","source":["cd /content/training_demo/pre-trained-models"],"metadata":{"id":"CpUh146b9sF7","executionInfo":{"status":"ok","timestamp":1666777850192,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c2029dc-1712-4106-e85a-3b536c9d5479"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo/pre-trained-models\n"]}]},{"cell_type":"code","source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kn0sU53hM8ii","executionInfo":{"status":"ok","timestamp":1666777857251,"user_tz":-330,"elapsed":3376,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"f634213e-70cc-4d85-995e-ecc2aab1ae12"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-10-26 09:52:53--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.145.128, 2a00:1450:4013:c01::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.145.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 386527459 (369M) [application/x-tar]\n","Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n","\n","ssd_resnet101_v1_fp 100%[===================>] 368.62M   139MB/s    in 2.7s    \n","\n","2022-10-26 09:52:56 (139 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n","\n"]}]},{"cell_type":"code","source":["!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RD3fIerdNoNV","executionInfo":{"status":"ok","timestamp":1666777875227,"user_tz":-330,"elapsed":4712,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"21d2e40b-33d4-4926-c232-2f32349f061e"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vb_TNptuOCXp","executionInfo":{"status":"ok","timestamp":1666777919834,"user_tz":-330,"elapsed":900,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"62d23731-ed53-41b8-ddcc-a1ce0e67f0bb"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training_demo/pre-trained-models'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["cd /content/training_demo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0QvWdO0hONyD","executionInfo":{"status":"ok","timestamp":1666777922971,"user_tz":-330,"elapsed":585,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"dd6ad720-6a59-4a64-c267-d6ff061bd9b9"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/training_demo\n"]}]},{"cell_type":"code","source":["# Create train data:\n","!python generate_tfrecord.py -x /content/training_demo/images/train -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/train.record\n","\n","# Create test data:\n","!python generate_tfrecord.py -x /content/training_demo/images/test -l /content/training_demo/annotations/label_map.pbtxt -o /content/training_demo/annotations/test.record"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HFhBUJK-QR3S","executionInfo":{"status":"ok","timestamp":1666777971884,"user_tz":-330,"elapsed":6946,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"4f20d0c5-d61b-4503-bc5c-1ccb9f186a9c"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-26 09:54:45.150808: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Successfully created the TFRecord file: /content/training_demo/annotations/train.record\n","2022-10-26 09:54:48.581073: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Successfully created the TFRecord file: /content/training_demo/annotations/test.record\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"-jYBzHM6QdNu","executionInfo":{"status":"ok","timestamp":1666777975816,"user_tz":-330,"elapsed":472,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"f1fb3c4b-8703-436f-f593-0c718be1dfcf"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training_demo'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BX2Xz-LUiV7","executionInfo":{"status":"ok","timestamp":1666777978285,"user_tz":-330,"elapsed":5,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"c7262ac6-28e8-4e84-94a4-f50a1f92a2f8"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  model_main_tf2.py\n","\u001b[01;34mexported-models\u001b[0m/     generate_tfrecord.py        \u001b[01;34mmodels\u001b[0m/\n","exporter_main_v2.py  \u001b[01;34mimages\u001b[0m/                     \u001b[01;34mpre-trained-models\u001b[0m/\n"]}]},{"cell_type":"code","source":["!python model_main_tf2.py --model_dir=/content/training_demo/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vwixbvpQUqpJ","executionInfo":{"status":"ok","timestamp":1666782223285,"user_tz":-330,"elapsed":3796411,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"0e60e8cb-3750-4a17-ec56-f81e141fdfbc"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-26 10:02:26.153832: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-26 10:02:27.002880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-26 10:02:27.002999: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-26 10:02:27.003019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-10-26 10:02:30.340650: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I1026 10:02:30.358378 140336310814592 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I1026 10:02:30.363888 140336310814592 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I1026 10:02:30.364068 140336310814592 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W1026 10:02:30.393169 140336310814592 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n","I1026 10:02:30.401169 140336310814592 dataset_builder.py:162] Reading unweighted datasets: ['/content/training_demo/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n","I1026 10:02:30.401478 140336310814592 dataset_builder.py:79] Reading record datasets for input file: ['/content/training_demo/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I1026 10:02:30.401596 140336310814592 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W1026 10:02:30.401673 140336310814592 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W1026 10:02:30.408068 140336310814592 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W1026 10:02:30.426966 140336310814592 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W1026 10:02:37.689590 140336310814592 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W1026 10:02:40.766592 140336310814592 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W1026 10:02:42.556051 140336310814592 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.767269 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.770421 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.773277 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.774481 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.777244 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.778292 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.782739 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.783843 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.785428 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I1026 10:03:26.786443 140336310814592 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W1026 10:03:28.917034 140331857200896 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 2.450s\n","I1026 10:07:33.518734 140336310814592 model_lib_v2.py:707] Step 100 per-step time 2.450s\n","INFO:tensorflow:{'Loss/classification_loss': 0.3320412,\n"," 'Loss/localization_loss': 0.21759328,\n"," 'Loss/regularization_loss': 1.1257551,\n"," 'Loss/total_loss': 1.6753895,\n"," 'learning_rate': 0.014666351}\n","I1026 10:07:33.519118 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.3320412,\n"," 'Loss/localization_loss': 0.21759328,\n"," 'Loss/regularization_loss': 1.1257551,\n"," 'Loss/total_loss': 1.6753895,\n"," 'learning_rate': 0.014666351}\n","INFO:tensorflow:Step 200 per-step time 1.827s\n","I1026 10:10:36.199376 140336310814592 model_lib_v2.py:707] Step 200 per-step time 1.827s\n","INFO:tensorflow:{'Loss/classification_loss': 0.30236778,\n"," 'Loss/localization_loss': 0.09523977,\n"," 'Loss/regularization_loss': 1.1129516,\n"," 'Loss/total_loss': 1.5105592,\n"," 'learning_rate': 0.0159997}\n","I1026 10:10:36.199782 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.30236778,\n"," 'Loss/localization_loss': 0.09523977,\n"," 'Loss/regularization_loss': 1.1129516,\n"," 'Loss/total_loss': 1.5105592,\n"," 'learning_rate': 0.0159997}\n","INFO:tensorflow:Step 300 per-step time 1.840s\n","I1026 10:13:40.242763 140336310814592 model_lib_v2.py:707] Step 300 per-step time 1.840s\n","INFO:tensorflow:{'Loss/classification_loss': 0.27872512,\n"," 'Loss/localization_loss': 0.08476254,\n"," 'Loss/regularization_loss': 1.0990114,\n"," 'Loss/total_loss': 1.4624991,\n"," 'learning_rate': 0.01733305}\n","I1026 10:13:40.243097 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.27872512,\n"," 'Loss/localization_loss': 0.08476254,\n"," 'Loss/regularization_loss': 1.0990114,\n"," 'Loss/total_loss': 1.4624991,\n"," 'learning_rate': 0.01733305}\n","INFO:tensorflow:Step 400 per-step time 1.854s\n","I1026 10:16:45.651147 140336310814592 model_lib_v2.py:707] Step 400 per-step time 1.854s\n","INFO:tensorflow:{'Loss/classification_loss': 0.21203266,\n"," 'Loss/localization_loss': 0.078945294,\n"," 'Loss/regularization_loss': 1.0841063,\n"," 'Loss/total_loss': 1.3750843,\n"," 'learning_rate': 0.0186664}\n","I1026 10:16:45.651494 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.21203266,\n"," 'Loss/localization_loss': 0.078945294,\n"," 'Loss/regularization_loss': 1.0841063,\n"," 'Loss/total_loss': 1.3750843,\n"," 'learning_rate': 0.0186664}\n","INFO:tensorflow:Step 500 per-step time 1.834s\n","I1026 10:19:49.052362 140336310814592 model_lib_v2.py:707] Step 500 per-step time 1.834s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1819993,\n"," 'Loss/localization_loss': 0.027836476,\n"," 'Loss/regularization_loss': 1.0681365,\n"," 'Loss/total_loss': 1.2779722,\n"," 'learning_rate': 0.01999975}\n","I1026 10:19:49.052710 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.1819993,\n"," 'Loss/localization_loss': 0.027836476,\n"," 'Loss/regularization_loss': 1.0681365,\n"," 'Loss/total_loss': 1.2779722,\n"," 'learning_rate': 0.01999975}\n","INFO:tensorflow:Step 600 per-step time 1.834s\n","I1026 10:22:52.498023 140336310814592 model_lib_v2.py:707] Step 600 per-step time 1.834s\n","INFO:tensorflow:{'Loss/classification_loss': 0.18253638,\n"," 'Loss/localization_loss': 0.039562613,\n"," 'Loss/regularization_loss': 1.0512866,\n"," 'Loss/total_loss': 1.2733855,\n"," 'learning_rate': 0.0213331}\n","I1026 10:22:52.498383 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.18253638,\n"," 'Loss/localization_loss': 0.039562613,\n"," 'Loss/regularization_loss': 1.0512866,\n"," 'Loss/total_loss': 1.2733855,\n"," 'learning_rate': 0.0213331}\n","INFO:tensorflow:Step 700 per-step time 1.835s\n","I1026 10:25:55.996105 140336310814592 model_lib_v2.py:707] Step 700 per-step time 1.835s\n","INFO:tensorflow:{'Loss/classification_loss': 0.20953564,\n"," 'Loss/localization_loss': 0.047910742,\n"," 'Loss/regularization_loss': 1.0335134,\n"," 'Loss/total_loss': 1.2909598,\n"," 'learning_rate': 0.02266645}\n","I1026 10:25:55.996468 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.20953564,\n"," 'Loss/localization_loss': 0.047910742,\n"," 'Loss/regularization_loss': 1.0335134,\n"," 'Loss/total_loss': 1.2909598,\n"," 'learning_rate': 0.02266645}\n","INFO:tensorflow:Step 800 per-step time 1.833s\n","I1026 10:28:59.319299 140336310814592 model_lib_v2.py:707] Step 800 per-step time 1.833s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13625158,\n"," 'Loss/localization_loss': 0.03145863,\n"," 'Loss/regularization_loss': 1.0151305,\n"," 'Loss/total_loss': 1.1828407,\n"," 'learning_rate': 0.023999799}\n","I1026 10:28:59.319636 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.13625158,\n"," 'Loss/localization_loss': 0.03145863,\n"," 'Loss/regularization_loss': 1.0151305,\n"," 'Loss/total_loss': 1.1828407,\n"," 'learning_rate': 0.023999799}\n","INFO:tensorflow:Step 900 per-step time 1.838s\n","I1026 10:32:03.170866 140336310814592 model_lib_v2.py:707] Step 900 per-step time 1.838s\n","INFO:tensorflow:{'Loss/classification_loss': 0.121561095,\n"," 'Loss/localization_loss': 0.019443266,\n"," 'Loss/regularization_loss': 0.99592245,\n"," 'Loss/total_loss': 1.1369268,\n"," 'learning_rate': 0.025333151}\n","I1026 10:32:03.171233 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.121561095,\n"," 'Loss/localization_loss': 0.019443266,\n"," 'Loss/regularization_loss': 0.99592245,\n"," 'Loss/total_loss': 1.1369268,\n"," 'learning_rate': 0.025333151}\n","INFO:tensorflow:Step 1000 per-step time 1.840s\n","I1026 10:35:07.192434 140336310814592 model_lib_v2.py:707] Step 1000 per-step time 1.840s\n","INFO:tensorflow:{'Loss/classification_loss': 0.11102416,\n"," 'Loss/localization_loss': 0.017229754,\n"," 'Loss/regularization_loss': 0.9761229,\n"," 'Loss/total_loss': 1.1043768,\n"," 'learning_rate': 0.0266665}\n","I1026 10:35:07.192787 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.11102416,\n"," 'Loss/localization_loss': 0.017229754,\n"," 'Loss/regularization_loss': 0.9761229,\n"," 'Loss/total_loss': 1.1043768,\n"," 'learning_rate': 0.0266665}\n","INFO:tensorflow:Step 1100 per-step time 1.883s\n","I1026 10:38:15.444520 140336310814592 model_lib_v2.py:707] Step 1100 per-step time 1.883s\n","INFO:tensorflow:{'Loss/classification_loss': 0.09644179,\n"," 'Loss/localization_loss': 0.015630702,\n"," 'Loss/regularization_loss': 0.95570886,\n"," 'Loss/total_loss': 1.0677813,\n"," 'learning_rate': 0.02799985}\n","I1026 10:38:15.444872 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.09644179,\n"," 'Loss/localization_loss': 0.015630702,\n"," 'Loss/regularization_loss': 0.95570886,\n"," 'Loss/total_loss': 1.0677813,\n"," 'learning_rate': 0.02799985}\n","INFO:tensorflow:Step 1200 per-step time 1.834s\n","I1026 10:41:18.813773 140336310814592 model_lib_v2.py:707] Step 1200 per-step time 1.834s\n","INFO:tensorflow:{'Loss/classification_loss': 0.10439151,\n"," 'Loss/localization_loss': 0.016562818,\n"," 'Loss/regularization_loss': 0.9347193,\n"," 'Loss/total_loss': 1.0556736,\n"," 'learning_rate': 0.0293332}\n","I1026 10:41:18.814096 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.10439151,\n"," 'Loss/localization_loss': 0.016562818,\n"," 'Loss/regularization_loss': 0.9347193,\n"," 'Loss/total_loss': 1.0556736,\n"," 'learning_rate': 0.0293332}\n","INFO:tensorflow:Step 1300 per-step time 1.818s\n","I1026 10:44:20.632152 140336310814592 model_lib_v2.py:707] Step 1300 per-step time 1.818s\n","INFO:tensorflow:{'Loss/classification_loss': 0.068125054,\n"," 'Loss/localization_loss': 0.010788124,\n"," 'Loss/regularization_loss': 0.91324246,\n"," 'Loss/total_loss': 0.9921557,\n"," 'learning_rate': 0.03066655}\n","I1026 10:44:20.632654 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.068125054,\n"," 'Loss/localization_loss': 0.010788124,\n"," 'Loss/regularization_loss': 0.91324246,\n"," 'Loss/total_loss': 0.9921557,\n"," 'learning_rate': 0.03066655}\n","INFO:tensorflow:Step 1400 per-step time 1.811s\n","I1026 10:47:21.738282 140336310814592 model_lib_v2.py:707] Step 1400 per-step time 1.811s\n","INFO:tensorflow:{'Loss/classification_loss': 0.075452924,\n"," 'Loss/localization_loss': 0.010961161,\n"," 'Loss/regularization_loss': 0.89140177,\n"," 'Loss/total_loss': 0.97781587,\n"," 'learning_rate': 0.0319999}\n","I1026 10:47:21.738600 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.075452924,\n"," 'Loss/localization_loss': 0.010961161,\n"," 'Loss/regularization_loss': 0.89140177,\n"," 'Loss/total_loss': 0.97781587,\n"," 'learning_rate': 0.0319999}\n","INFO:tensorflow:Step 1500 per-step time 1.812s\n","I1026 10:50:22.986451 140336310814592 model_lib_v2.py:707] Step 1500 per-step time 1.812s\n","INFO:tensorflow:{'Loss/classification_loss': 0.088174015,\n"," 'Loss/localization_loss': 0.0115324315,\n"," 'Loss/regularization_loss': 0.86931103,\n"," 'Loss/total_loss': 0.9690175,\n"," 'learning_rate': 0.03333325}\n","I1026 10:50:22.986816 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.088174015,\n"," 'Loss/localization_loss': 0.0115324315,\n"," 'Loss/regularization_loss': 0.86931103,\n"," 'Loss/total_loss': 0.9690175,\n"," 'learning_rate': 0.03333325}\n","INFO:tensorflow:Step 1600 per-step time 1.815s\n","I1026 10:53:24.501810 140336310814592 model_lib_v2.py:707] Step 1600 per-step time 1.815s\n","INFO:tensorflow:{'Loss/classification_loss': 0.080430664,\n"," 'Loss/localization_loss': 0.013293647,\n"," 'Loss/regularization_loss': 0.84681034,\n"," 'Loss/total_loss': 0.94053465,\n"," 'learning_rate': 0.034666598}\n","I1026 10:53:24.502113 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.080430664,\n"," 'Loss/localization_loss': 0.013293647,\n"," 'Loss/regularization_loss': 0.84681034,\n"," 'Loss/total_loss': 0.94053465,\n"," 'learning_rate': 0.034666598}\n","INFO:tensorflow:Step 1700 per-step time 1.814s\n","I1026 10:56:25.894589 140336310814592 model_lib_v2.py:707] Step 1700 per-step time 1.814s\n","INFO:tensorflow:{'Loss/classification_loss': 0.091311954,\n"," 'Loss/localization_loss': 0.009233398,\n"," 'Loss/regularization_loss': 0.8239158,\n"," 'Loss/total_loss': 0.9244611,\n"," 'learning_rate': 0.03599995}\n","I1026 10:56:25.894901 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.091311954,\n"," 'Loss/localization_loss': 0.009233398,\n"," 'Loss/regularization_loss': 0.8239158,\n"," 'Loss/total_loss': 0.9244611,\n"," 'learning_rate': 0.03599995}\n","INFO:tensorflow:Step 1800 per-step time 1.817s\n","I1026 10:59:27.572810 140336310814592 model_lib_v2.py:707] Step 1800 per-step time 1.817s\n","INFO:tensorflow:{'Loss/classification_loss': 0.07430819,\n"," 'Loss/localization_loss': 0.010461301,\n"," 'Loss/regularization_loss': 0.80091774,\n"," 'Loss/total_loss': 0.88568723,\n"," 'learning_rate': 0.037333302}\n","I1026 10:59:27.573112 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.07430819,\n"," 'Loss/localization_loss': 0.010461301,\n"," 'Loss/regularization_loss': 0.80091774,\n"," 'Loss/total_loss': 0.88568723,\n"," 'learning_rate': 0.037333302}\n","INFO:tensorflow:Step 1900 per-step time 1.835s\n","I1026 11:02:31.052068 140336310814592 model_lib_v2.py:707] Step 1900 per-step time 1.835s\n","INFO:tensorflow:{'Loss/classification_loss': 0.078644566,\n"," 'Loss/localization_loss': 0.015347119,\n"," 'Loss/regularization_loss': 0.7777843,\n"," 'Loss/total_loss': 0.871776,\n"," 'learning_rate': 0.03866665}\n","I1026 11:02:31.052509 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.078644566,\n"," 'Loss/localization_loss': 0.015347119,\n"," 'Loss/regularization_loss': 0.7777843,\n"," 'Loss/total_loss': 0.871776,\n"," 'learning_rate': 0.03866665}\n","INFO:tensorflow:Step 2000 per-step time 1.836s\n","I1026 11:05:34.623290 140336310814592 model_lib_v2.py:707] Step 2000 per-step time 1.836s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0662263,\n"," 'Loss/localization_loss': 0.008972293,\n"," 'Loss/regularization_loss': 0.7545,\n"," 'Loss/total_loss': 0.82969856,\n"," 'learning_rate': nan}\n","I1026 11:05:34.623619 140336310814592 model_lib_v2.py:708] {'Loss/classification_loss': 0.0662263,\n"," 'Loss/localization_loss': 0.008972293,\n"," 'Loss/regularization_loss': 0.7545,\n"," 'Loss/total_loss': 0.82969856,\n"," 'learning_rate': nan}\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"id":"r1yokCSLV4Gi","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1666782391739,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"bd924905-c2e6-400a-d21c-28b353f133ec"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/training_demo'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/training_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/training_demo/models/my_ssd_resnet101_v1_fpn --output_directory /content/training_demo/exported_models/my_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxGr67FK-OdE","executionInfo":{"status":"ok","timestamp":1666782811272,"user_tz":-330,"elapsed":85173,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"9f31067e-3aa8-4cc8-cb8c-e22841473ff4"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-10-26 11:14:06.038406: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-10-26 11:14:07.901476: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-26 11:14:07.901638: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-10-26 11:14:07.901658: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-10-26 11:14:13.516966: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W1026 11:14:13.814851 140364977887104 deprecation.py:628] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa8b06ff910>, because it is not built.\n","W1026 11:14:38.970997 140364977887104 save_impl.py:68] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa8b06ff910>, because it is not built.\n","W1026 11:15:15.378818 140364977887104 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n","I1026 11:15:26.703881 140364977887104 builder_impl.py:780] Assets written to: /content/training_demo/exported_models/my_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n","I1026 11:15:28.224298 140364977887104 config_util.py:254] Writing pipeline config file to /content/training_demo/exported_models/my_model/pipeline.config\n"]}]},{"cell_type":"markdown","source":["##**Inferencing Training Model**"],"metadata":{"id":"XYclZ7cJ___I"}},{"cell_type":"code","source":["\n","\"\"\"\n","Object Detection (On Image) From TF2 Saved Model\n","=====================================\n","\"\"\"\n","\n","import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import pathlib\n","import tensorflow as tf\n","import cv2\n","import argparse\n","from google.colab.patches import cv2_imshow\n","\n","# Enable GPU dynamic memory allocation\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# PROVIDE PATH TO IMAGE DIRECTORY\n","IMAGE_PATHS = '/content/training_demo/images/train/image17.jpg'\n","\n","\n","# PROVIDE PATH TO MODEL DIRECTORY\n","PATH_TO_MODEL_DIR = '/content/training_demo/exported_models/my_model'\n","\n","# PROVIDE PATH TO LABEL MAP\n","PATH_TO_LABELS = '/content/training_demo/annotations/label_map.pbtxt'\n","\n","# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n","MIN_CONF_THRESH = float(0.60)\n","\n","# LOAD THE MODEL\n","\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))\n","\n","# LOAD LABEL MAP DATA FOR PLOTTING\n","\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","                                                                    use_display_name=True)\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","    Args:\n","      path: the file path to the image\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))\n","\n","\n","\n","\n","print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n","\n","image = cv2.imread(IMAGE_PATHS)\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","input_tensor = tf.convert_to_tensor(image)\n","# The model expects a batch of images, so add an axis with `tf.newaxis`.\n","input_tensor = input_tensor[tf.newaxis, ...]\n","\n","# input_tensor = np.expand_dims(image_np, 0)\n","detections = detect_fn(input_tensor)\n","\n","# All outputs are batches tensors.\n","# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","# We're only interested in the first num_detections.\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","               for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","image_with_detections = image.copy()\n","\n","# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_with_detections,\n","      detections['detection_boxes'],\n","      detections['detection_classes'],\n","      detections['detection_scores'],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=0.5,\n","      agnostic_mode=False)\n","\n","print('Done')\n","# DISPLAYS OUTPUT IMAGE\n","cv2_imshow(image_with_detections)\n","# CLOSES WINDOW ONCE KEY IS PRESSED\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":988,"output_embedded_package_id":"1D8GgeB3kFUtfx1LGWdmF67OxBTZ9TgKG"},"id":"QzcAPOGI_gIY","executionInfo":{"status":"ok","timestamp":1666783268761,"user_tz":-330,"elapsed":33117,"user":{"displayName":"Rishikesh Raj Nair","userId":"07656817369192666451"}},"outputId":"07901cb8-7cbd-4bb6-87b5-c77760ae019c"},"execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}